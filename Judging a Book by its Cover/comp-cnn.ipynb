{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nimport pandas as pd\nimport numpy as np\nimport copy\n# import torch\nfrom torch.utils.data import Dataset\n# from torchvision import datasets\nimport torchvision\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\nfrom torchvision.io import read_image\nimport torchvision.models as models\n# from torch.autograd import Variable","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:08:55.784690Z","iopub.execute_input":"2022-11-27T16:08:55.785113Z","iopub.status.idle":"2022-11-27T16:09:00.053549Z","shell.execute_reply.started":"2022-11-27T16:08:55.784994Z","shell.execute_reply":"2022-11-27T16:09:00.052370Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q efficientnet_pytorch","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:09:00.058404Z","iopub.execute_input":"2022-11-27T16:09:00.058945Z","iopub.status.idle":"2022-11-27T16:09:15.637675Z","shell.execute_reply.started":"2022-11-27T16:09:00.058906Z","shell.execute_reply":"2022-11-27T16:09:15.636421Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# pretrained models\nfrom efficientnet_pytorch import EfficientNet\nfrom PIL import Image\nfrom torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:09:46.039943Z","iopub.execute_input":"2022-11-27T16:09:46.040701Z","iopub.status.idle":"2022-11-27T16:09:46.045669Z","shell.execute_reply.started":"2022-11-27T16:09:46.040662Z","shell.execute_reply":"2022-11-27T16:09:46.044623Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"img_dir = '/kaggle/input/col774-2022/images/images/'\ntrain_path_x ='/kaggle/input/col774-2022/train_x.csv'\ntrain_path_y ='/kaggle/input/col774-2022/train_y.csv'\ntest_path_x = '/kaggle/input/col774-2022/non_comp_test_x.csv'\ntest_path_y = '/kaggle/input/col774-2022/non_comp_test_y.csv'\nfinal_test_path_x='/kaggle/input/col774-2022/comp_test_x.csv'\n","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:10:59.369131Z","iopub.execute_input":"2022-11-27T16:10:59.370308Z","iopub.status.idle":"2022-11-27T16:10:59.375720Z","shell.execute_reply.started":"2022-11-27T16:10:59.370254Z","shell.execute_reply":"2022-11-27T16:10:59.374569Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class BookCoverImageDataset(Dataset):\n    def __init__(self, train_path_x, train_path_y, img_dir,transform=None):\n        self.img_labels = pd.read_csv(train_path_y)\n        self.img_names  = pd.read_csv(train_path_x)\n        self.img_names  = self.img_names.set_index('Id')\n        self.img_labels = self.img_labels.set_index('Id')\n        self.img_dir = img_dir\n        self.xtransform=transform\n        # self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])    \n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):        \n        img_path = os.path.join(self.img_dir, self.img_names['Cover_image_name'][idx])\n        image = Image.open(img_path)\n#         image = image/255.0\n        # image = self.normalize(image)\n        image =self.xtransform(image)\n        label = self.img_labels['Genre'][idx]\n        # features = feature_extractor(image)\n        label=torch.tensor(label)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:11:08.005281Z","iopub.execute_input":"2022-11-27T16:11:08.005676Z","iopub.status.idle":"2022-11-27T16:11:08.017314Z","shell.execute_reply.started":"2022-11-27T16:11:08.005644Z","shell.execute_reply":"2022-11-27T16:11:08.015970Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Preprocess image\nmodel_name = 'efficientnet-b3'\nimage_size = EfficientNet.get_image_size(model_name) # 300\ntfms = transforms.Compose([transforms.Resize(image_size), transforms.CenterCrop(image_size), \n                           transforms.ToTensor(),\n                           transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n# img = tfms(img).unsqueeze(0)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:11:20.276984Z","iopub.execute_input":"2022-11-27T16:11:20.277410Z","iopub.status.idle":"2022-11-27T16:11:20.285366Z","shell.execute_reply.started":"2022-11-27T16:11:20.277375Z","shell.execute_reply":"2022-11-27T16:11:20.284099Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"training_data = BookCoverImageDataset(train_path_x, train_path_y, img_dir,tfms)\ntest_data = BookCoverImageDataset(test_path_x, test_path_y, img_dir,tfms)\ntrain_dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\ntest_dataloader  = DataLoader(test_data, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:11:29.330662Z","iopub.execute_input":"2022-11-27T16:11:29.331066Z","iopub.status.idle":"2022-11-27T16:11:29.509271Z","shell.execute_reply.started":"2022-11-27T16:11:29.331021Z","shell.execute_reply":"2022-11-27T16:11:29.508309Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = EfficientNet.from_pretrained('efficientnet-b3')","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:11:35.861106Z","iopub.execute_input":"2022-11-27T16:11:35.861488Z","iopub.status.idle":"2022-11-27T16:11:37.493710Z","shell.execute_reply.started":"2022-11-27T16:11:35.861454Z","shell.execute_reply":"2022-11-27T16:11:37.492343Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b3-5fb5a3c3.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/47.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d073ceba8a348e0b60e3fa86c07dbff"}},"metadata":{}},{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b3\n","output_type":"stream"}]},{"cell_type":"code","source":"num_classes = 30\nmodel._fc=nn.Linear(in_features=1536, out_features=num_classes, bias=True)\nmodel._fc","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:17:47.987935Z","iopub.execute_input":"2022-11-27T16:17:47.988694Z","iopub.status.idle":"2022-11-27T16:17:47.998133Z","shell.execute_reply.started":"2022-11-27T16:17:47.988654Z","shell.execute_reply":"2022-11-27T16:17:47.996742Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"fine_tune = True\nfor params in model.parameters():\n    params.requires_grad = True\nnum_classes = 30","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:58:55.178908Z","iopub.execute_input":"2022-11-27T16:58:55.179621Z","iopub.status.idle":"2022-11-27T16:58:55.186556Z","shell.execute_reply.started":"2022-11-27T16:58:55.179584Z","shell.execute_reply":"2022-11-27T16:58:55.185306Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def accuracy(model, dataloader):\n    softmax = nn.Softmax(dim=1)\n    model.eval()\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')    \n    correct = 0.0\n    with torch.no_grad():    \n        for x,y in dataloader:\n            train_x, train_y = x, y#batch[0], batch[1]\n            train_x = train_x.to(device)\n            train_y = train_y.to(device)\n            logits = model(train_x)        \n#             _, preds = torch.max(output.data, 1)\n            preds=softmax(logits)\n            correct += (preds.argmax(1) == train_y).type(torch.float).sum().item()\n    return (correct/len(dataloader.dataset))*100","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:58:59.465434Z","iopub.execute_input":"2022-11-27T16:58:59.465817Z","iopub.status.idle":"2022-11-27T16:58:59.473467Z","shell.execute_reply.started":"2022-11-27T16:58:59.465785Z","shell.execute_reply":"2022-11-27T16:58:59.472535Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def train(model, train_dataloader, val_dataloader, optimizer, loss_fn, epochs=10, verbose=True, checkpoint=1):\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')    \n    model.to(device)\n    loss_fn.to(device)\n    model.train()\n    best_model, best_score = None, 0.0\n\n    loss_vals, val_accuracy, train_accuracy = [], [], []\n    for epoch in range(epochs):    \n        correct = 0.0\n        model.train()    \n        epoch_loss = 0.0\n        cnt=0\n        for batch,(x,y) in enumerate(train_dataloader):                        \n            train_x, train_y = x,y#batch[0], batch[1]\n            train_x = train_x.to(device)\n            train_y = train_y.to(device)\n            #fprop\n            outputs = model(train_x)\n            loss = loss_fn(outputs, train_y)\n            optimizer.zero_grad()\n            #bprop\n            loss.backward()\n            #update params\n            optimizer.step()\n            cnt+=1\n#             _, preds = torch.max(outputs.data, 1)\n#             correct += (preds == train_y).sum().item()\n            epoch_loss += loss.item()  \n#             print(loss.item())\n        \n#         train_acc = correct/len(train_dataloader.dataset)\n        \n        loss_vals.append(epoch_loss/cnt)\n        val_accuracy.append(accuracy(model, test_dataloader))\n        train_accuracy.append(accuracy(model, train_dataloader))\n\n        if best_score < val_accuracy[-1]:\n            best_score = val_accuracy[-1]\n            best_model = copy.deepcopy(model)            \n\n        if verbose and epoch%checkpoint == 0:                 \n            print('epoch = {}'.format(epoch))       \n            print('val_accuracy = {}'.format(val_accuracy[-1]))\n            print('train_accuracy = {}'.format(train_accuracy[-1]))                        \n            print('epoch loss = {}'.format(loss_vals[-1]))\n    return model,train_accuracy, val_accuracy, loss_vals","metadata":{"execution":{"iopub.status.busy":"2022-11-27T17:00:33.730277Z","iopub.execute_input":"2022-11-27T17:00:33.730652Z","iopub.status.idle":"2022-11-27T17:00:33.743156Z","shell.execute_reply.started":"2022-11-27T17:00:33.730621Z","shell.execute_reply":"2022-11-27T17:00:33.741926Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from time import time","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:59:16.284941Z","iopub.execute_input":"2022-11-27T16:59:16.285997Z","iopub.status.idle":"2022-11-27T16:59:16.291387Z","shell.execute_reply.started":"2022-11-27T16:59:16.285939Z","shell.execute_reply":"2022-11-27T16:59:16.289984Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"lr = 1e-3\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nloss_fn = nn.CrossEntropyLoss()\nt1=time()\nmodel,train_accuracy, val_accuracy, loss = train(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs=5)\nt=time()-t1\nprint('time',t)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T17:34:56.249695Z","iopub.execute_input":"2022-11-27T17:34:56.250133Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"epoch = 0\nval_accuracy = 22.54385964912281\ntrain_accuracy = 28.596491228070175\nepoch loss = 2.5876652634623345\nepoch = 1\nval_accuracy = 26.0\ntrain_accuracy = 35.45906432748538\nepoch loss = 2.420012412169361\n","output_type":"stream"}]},{"cell_type":"markdown","source":"epoch = 0\nval_accuracy = 21.263157894736842\ntrain_accuracy = 24.01169590643275\nepoch loss = 2.8328071044247434\ntime 1839.5948495864868","metadata":{}},{"cell_type":"code","source":"# save the model\nsave_path = '/kaggle/working/model_cnn.pth'\ntorch.save(model.state_dict(), save_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}