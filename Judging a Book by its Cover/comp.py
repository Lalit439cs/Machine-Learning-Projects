# -*- coding: utf-8 -*-
"""sub1-rnn_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12ityB9jp9XBidG6XKnIdG8fJj5iYdByX
"""

!pip install transformers

img_dir = '/kaggle/input/col774-2022/images/images/'
train_path_x ='/kaggle/input/col774-2022/train_x.csv'
train_path_y ='/kaggle/input/col774-2022/train_y.csv'
test_path_x = '/kaggle/input/col774-2022/non_comp_test_x.csv'
test_path_y = '/kaggle/input/col774-2022/non_comp_test_y.csv'
final_test_path_x='/kaggle/input/col774-2022/comp_test_x.csv'

import torch
from torch import nn
import pandas as pd
import numpy as np
from transformers import BertModel, BertConfig, BertTokenizer
from torch.utils.data import DataLoader, Dataset
from transformers import BertForSequenceClassification, Trainer, TrainingArguments
from transformers import AdamW

import os
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import pandas as pd
import numpy as np
import copy
# import torch
from torch.utils.data import Dataset
# from torchvision import datasets
import torchvision
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt
from torchvision.io import read_image
import torchvision.models as models
# from torch.autograd import Variable

!pip install -q efficientnet_pytorch

# pretrained models
from efficientnet_pytorch import EfficientNet
from PIL import Image
from torchvision import transforms

!CUBLAS_WORKSPACE_CONFIG=:4096:2
torch.backends.cudnn.deterministic = True
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

pretrained_model_name = 'bert-base-uncased'

tokenizer = BertTokenizer.from_pretrained(pretrained_model_name)

def get_data(path_x, path_y):
    title_info = pd.read_csv(path_x).set_index('Id')
    img_labels = pd.read_csv(path_y).set_index('Id')
    x, y = [], []
    for i in range(len(img_labels['Genre'])):
        title = title_info['Title'][i]
        img_label = img_labels['Genre'][i]
        x.append(title)
        y.append(int(img_label))
    return x, y

# train_x, train_y = get_data(train_path_x, train_path_y)
test_x, test_y   = get_data(test_path_x, test_path_y)

def get_data_comp(path_x):
    title_info = pd.read_csv(path_x).set_index('Id')
    x, y = [], []
    for i in range(len(title_info['Title'])):
        title = title_info['Title'][i]
        x.append(title)
        y.append(0)
    return x, y

comp_test_x, comp_test_y   = get_data_comp(final_test_path_x)

len(comp_test_x)

# train_encodings = tokenizer(train_x, truncation=True, padding=True, max_length=50)
num_labels = 30
test_encodings  = tokenizer(test_x, truncation=True, padding=True, max_length=50)

num_labels = 30
comp_test_encodings  = tokenizer(comp_test_x, truncation=True, padding=True, max_length=50)

# create the dataloaders
class TitleHeadingDataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels
    
    def __len__(self):
        return len(self.labels)
    
    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

class BookCoverImageDataset(Dataset):
    def __init__(self, train_path_x, train_path_y, img_dir,transform=None,typ='train'):
        
        self.img_names  = pd.read_csv(train_path_x)
        self.img_names  = self.img_names.set_index('Id')
        
        self.img_dir = img_dir
        self.xtransform=transform
        self.typ=typ#labels related var change
        if(self.typ=='train'):
            self.img_labels = pd.read_csv(train_path_y)
            self.img_labels = self.img_labels.set_index('Id')
        # self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])    

    def __len__(self):
        return len(self.img_names)

    def __getitem__(self, idx):        
        img_path = os.path.join(self.img_dir, self.img_names['Cover_image_name'][idx])
        image = Image.open(img_path)
#         image = image/255.0
        # image = self.normalize(image)
        if (self.xtransform):
            image =self.xtransform(image)
        else:
            print('other..')
            transform = transforms.Compose([transforms.ToTensor()])
            image = transform(image)
            image =image/255.0
        if (self.typ=='train'):
            label = self.img_labels['Genre'][idx]
        else:
            label=0
        # features = feature_extractor(image)
        label=torch.tensor(label)
        return image, label

# Preprocess image
model_name = 'efficientnet-b3'
image_size = EfficientNet.get_image_size(model_name) # 300
tfms = transforms.Compose([transforms.Resize(image_size), transforms.CenterCrop(image_size), 
                           transforms.ToTensor(),
                           transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])
# img = tfms(img).unsqueeze(0)

#rnn
# train_dataset = TitleHeadingDataset(train_encodings, train_y)
# train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)

#rnn
test_dataset = TitleHeadingDataset(test_encodings, test_y)
test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# #cnn
# cnn_training_data = BookCoverImageDataset(train_path_x, train_path_y, img_dir)
# cnn_train_dataloader = DataLoader(cnn_training_data, batch_size=16, shuffle=True)

cnn_test_data = BookCoverImageDataset(test_path_x, test_path_y, img_dir,tfms)
cnn_test_dataloader  = DataLoader(cnn_test_data, batch_size=32, shuffle=False)

#cnn 
#comp_test
fcnn_test_data = BookCoverImageDataset(final_test_path_x, test_path_y, img_dir,tfms,'test')
fcnn_test_dataloader  = DataLoader(fcnn_test_data, batch_size=32, shuffle=False)

# load the model
load_path = '/kaggle/input/models/Models/BertModel_fine_tuned_v1.pt'
model = BertForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=num_labels)
model.load_state_dict(torch.load(load_path))
model.to(device)
model.eval()

comp_test_dataset = TitleHeadingDataset(comp_test_encodings, comp_test_y)
comp_test_dataloader = DataLoader(comp_test_dataset, batch_size=64, shuffle=False)

# load the model_cnn
load_pt = '/kaggle/input/models/model_cnn.pth'
model_cnn = EfficientNet.from_pretrained('efficientnet-b3')
num_classes = 30
model_cnn._fc=nn.Linear(in_features=1536, out_features=num_classes, bias=True)
model_cnn.load_state_dict(torch.load(load_pt))
model_cnn.to(device)
model_cnn.eval()

# def train(train_dataloader, optimizer, given_model, epochs=100, model_name=pretrained_model_name, num_classes=30, verbose=True): # returns the trained model
#     device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
#     model = given_model
#     model.to(device)
#     model.train()

#     optim = optimizer(model.parameters(), lr=5e-5)
    
#     for epoch in range(epochs):        
#         batch_cnt = 0
#         for batch in train_dataloader:
#             batch_cnt += 1

#             optim.zero_grad()            
#             input_ids = batch['input_ids'].to(device)
#             attention_mask = batch['attention_mask'].to(device)
#             labels = batch['labels'].to(device)
#             outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
#             loss = outputs[0]
#             loss.backward()
#             optim.step()

#             if verbose and batch_cnt%100:
#                 print('loss = {}'.format(loss.item()))
    
#     return model

# model = train(train_dataloader, optimizer=AdamW, given_model=model, epochs=10)

# # save the model
# save_path = '/content/drive/MyDrive/ml_a4/BertModel_fine_tuned_v2.pt'
# torch.save(model.state_dict(), save_path)

# def accuracy(dataloader, model):     
#     softmax = nn.Softmax(dim=1)        
#     correct = 0.0
#     with torch.no_grad():    
#         for batch in dataloader:        
#             input_ids = batch['input_ids'].to(device)
#             attention_mask = batch['attention_mask'].to(device)
#             labels = batch['labels'].to(device)
#             output = model(input_ids, attention_mask=attention_mask, labels=labels)            
#             # apply softmax to output of model
#             preds = softmax(output['logits'])                        
            
#             # move logits to cpu
#             preds = preds.detach().cpu().numpy()
#             label_ids = labels.to('cpu').numpy()
            
#             # get correct classifications
#             correct += np.sum(label_ids == preds.argmax(1))            

#     return correct/len(dataloader.dataset)

# # train set accuracy
# print(accuracy(train_dataloader, model))
# # print(accuracy(test_dataloader, model))

# # test set accuracy
# print(accuracy(test_dataloader, model))

def get_predictions_rnn(dataloader, model):     
    softmax = nn.Softmax(dim=1)        
    outputs=[]
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
    with torch.no_grad():    
        for batch in dataloader:        
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            output = model(input_ids, attention_mask=attention_mask)#, labels=labels)         
            # apply softmax to output of model
            preds = softmax(output['logits'])                        
            # move logits to cpu
            preds = preds.detach().cpu().numpy()
            # get correct classifications
            outputs=outputs+list(preds)            

    return outputs

def get_predictions_cnn(dataloader, model):
    softmax = nn.Softmax(dim=1)
    model.eval()
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
    outputs=[]
    with torch.no_grad():    
        for x,y in dataloader:
            train_x, train_y = x, y#batch[0], batch[1]
            train_x = train_x.to(device)
            train_y = train_y.to(device)
            logits = model(train_x)        
#             _, preds = torch.max(output.data, 1)
            preds=softmax(logits)
            preds = preds.detach().cpu().numpy()
            # get correct classifications
            outputs=outputs+list(preds)            

    return outputs

p_rnn=get_predictions_rnn(test_dataloader,model)

p_rnn=np.array(p_rnn)
p_rnn.shape

p_cnn=get_predictions_cnn(cnn_test_dataloader,model_cnn)

p_cnn=np.array(p_cnn)
p_cnn.shape

pf_rnn=get_predictions_rnn(comp_test_dataloader,model)

pf_cnn=get_predictions_cnn(fcnn_test_dataloader,model_cnn)

pf_rnn=np.array(pf_rnn)
print(pf_rnn.shape)

pf_cnn=np.array(pf_cnn)
print(pf_cnn.shape)

#final 
pf = np.hstack((pf_rnn,pf_cnn))
pf.shape

np.save ('/kaggle/working/final_px.npy',pf)

pf=np.load('/kaggle/input/models/final_px_1.npy')

p=np.hstack((p_rnn,p_cnn))
yp=np.array(test_y)

np.save ('/kaggle/working/val_px_1.npy',p)
np.save ('/kaggle/working/val_y_1.npy',yp)

p=np.load('/kaggle/input/models/val_px_1.npy')
yp=np.load('/kaggle/input/models/val_y_1.npy')

#actual train data
pt=np.load('/kaggle/input/models/train_px_1.npy')
ypt=np.load('/kaggle/input/models/train_y_1.npy')

pt.shape

print(p.shape)
yp.shape

classes=30
gamma=0.001
k=5

from time import time
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

#gaussian_libsvm
t1=time()
svm_main =SVC(C=1.0,kernel ='rbf',gamma =0.001,verbose =True,tol=1e-5,decision_function_shape='ovo')#break_ties
clf = make_pipeline(StandardScaler(), svm_main)
classifier=clf.fit(p,yp)
t=time()-t1

#details-
classes=svm_main.classes_
print("classes-")
print(classes)
print('fit_status',svm_main.fit_status_)
nf =svm_main.n_features_in_
print('n_features_in_',nf)

#train acc-val
acc=clf.score(p,yp)
print("training time",t)
print("test accuracy",acc*100)
#confusion matrix

#loaded p,yp data

from sklearn.model_selection import GridSearchCV

#GridSearch
#5-fold cross validation-
svm_main =SVC(decision_function_shape='ovr')#break_ties
cross_k=5
cvals =[1e-5,1e-3,1,5,10]
gammas = [1,0.1,0.01,0.001]
t1=time()
params_grid={'C':cvals,'gamma':gammas,'kernel': ['rbf'],'tol':[1e-5]}
clf = GridSearchCV(svm_main,params_grid,cv =cross_k)

clf.fit(p,yp)
t=time()-t1
#plots

print('best_estimator_')
print(clf.best_estimator_)

print('best_score_')
print(clf.best_score_)

print('best_params_')
print(clf.best_params_)

print('best_index_',clf.best_index_)

print('scorer_',clf.scorer_)
#train acc-val

#train acc-val
acc=clf.score(p,yp)
print("training time",t)
print(" accuracy",acc*100)
#confusion matrix

acc=clf.score(pt,ypt)
print(" train accuracy",acc*100)

clf.cv_results_

type(clf.cv_results_)

df= pd.DataFrame(clf.cv_results_)

groups = df.groupby(by=['param_kernel', 'param_tol'])
groups.get_group(('rbf', 1e-5))

yp.shape

pn =np.vstack((pt,p))
ypn =np.vstack((ypt.reshape(-1,1),yp.reshape(-1,1)))
print(pn.shape)
print(ypn.shape)

ypn =ypn.reshape(-1)

#best model according to gridsearch
#gaussian_libsvm-ovr?
t1=time()
clf =SVC(C=1.0,kernel ='linear',gamma =1.0,tol=1e-5,decision_function_shape='ovo')#break_ties
clf.fit(pn,ypn)
t=time()-t1

t1=time()
from sklearn.linear_model import SGDClassifier
clf=SGDClassifier(max_iter=200, warm_start=True,tol=1e-5)
clf.fit(pt,ypt)
t=time()-t1

clf.partial_fit(p,yp)

#train acc-val
acc=clf.score(pt,ypt)
print("training time",t)
print(" accuracy",acc*100)

#train acc-val
acc=clf.score(pn,ypn)
print("training time",t)
print(" accuracy",acc*100)

#train acc-tn
acc=clf.score(p,yp)
print(" accuracy",acc*100)

clf=clf.best_estimator_

clf

import pickle
filename = '/kaggle/working/final_model_lr_c1g1.sav'
# filename='/kaggle/input/models/final_model_gc.sav'

# save the model
pickle.dump(clf, open(filename, 'wb'))

# load the model 
clf0 = pickle.load(open(filename, 'rb'))

clf0

#train acc-tn
acc=clf0.score(pt,ypt)
print(" accuracy",acc*100)

def get_predictions_rnn_only(dataloader, model):     
    softmax = nn.Softmax(dim=1)        
    outputs=[]
    with torch.no_grad():    
        for batch in dataloader:        
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            output = model(input_ids, attention_mask=attention_mask)#, labels=labels)         
            # apply softmax to output of model
            preds = softmax(output['logits'])                        
            # move logits to cpu
            preds = preds.detach().cpu().numpy()
            # get correct classifications
            outputs=outputs+list(preds.argmax(1).reshape(-1))            

    return outputs
y_outs=get_predictions(comp_test_dataloader,model)

#final -f
yf =clf0.predict(pf)

#final -above
yf =clf.predict(pf)

clf

pf.shape

class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(in_features=60, out_features=70),
            nn.ReLU(),
            nn.Linear(in_features=70, out_features=50),
            nn.ReLU(),
            nn.Linear(in_features=50, out_features=30)
            #             nn.ReLU(),
            #             nn.Linear(in_features=30, out_features=30)        
        )

    def forward(self, x):
        return self.network(x)

NeuralNetwork()

load_path="/kaggle/input/models/Neuralnet_v1_1_fn.pt"
model = NeuralNetwork().to(device)
model.load_state_dict(torch.load(load_path))
model.eval()
model

def get_predictions_rnn_only(dataloader, model):     
    softmax = nn.Softmax(dim=1)        
    outputs=[]
    with torch.no_grad():    
        for batch in dataloader:        
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            output = model(input_ids, attention_mask=attention_mask)#, labels=labels)         
            # apply softmax to output of model
            preds = softmax(output['logits'])                        
            # move logits to cpu
            preds = preds.detach().cpu().numpy()
            # get correct classifications
            outputs=outputs+list(preds.argmax(1).reshape(-1))            

    return outputs
y_outs=get_predictions(comp_test_dataloader,model)

def get_preds_from_nn(dataloader, model):     
    device  = "cuda" if torch.cuda.is_available() else "cpu"
    softmax = nn.Softmax(dim=1)        
    correct = 0.0
    outputs = []
    with torch.no_grad():    
        for (X, y) in dataloader:        
            X = X.to(device)
            # y = y.to(device)
            out = model(X)
            preds = softmax(out)
            preds = preds.detach().cpu().numpy()
#             y = y.to('cpu').numpy()
#             correct += np.sum(y == preds.argmax(1))          
            outputs=outputs+list(preds.argmax(1).reshape(-1))            
    return outputs

n =len(pf)
train_y_nn=[0 for i in range(n)]

features_train = torch.tensor(pf)
targets_train  = torch.tensor(train_y_nn)
dataset_train = torch.utils.data.TensorDataset(features_train, targets_train)
final_dataloader = DataLoader(dataset_train, batch_size=100, shuffle=False)

yf=get_preds_from_nn(final_dataloader,model)

len(yf)

y_outs=list(yf)
df =pd.read_csv(final_test_path_x)
dicti={'Id':df['Id'],'Genre':y_outs}
df_out=pd.DataFrame(dicti)

df_out.to_csv('/kaggle/working/final_test_y7.csv',index =False)

df1 = pd.read_csv('/kaggle/working/final_test_y7.csv')

df1.head()

df1.head()